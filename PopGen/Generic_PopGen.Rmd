---
title: "Pop Gen Analyses"
output: html_document
date: "2025-05-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Packages
```{r load packages}
if (!requireNamespace("BiocManager", quietly=TRUE))
  install.packages("BiocManager")
BiocManager::install("SNPRelate")
devtools::install_github("thierrygosselin/radiator")

library(devtools)
library(tidyverse)
library(dartR) #this calls SNPrelate as a dependency
library(poppr)
library(vcfR)
library(adegenet)
library(hierfstat)
library(pophelper) #not on CRAN
library(gridExtra)
library(ggpubr)
#library(strataG) #not on CRAN
library(mapdata)
library(viridis)
library(wesanderson)
library(ape)
library(reshape2)
library(Matrix)
library(sf)
library(ggplot2)
library(ggspatial)
library(plotly)
library(MetBrewer)
library(patchwork)
library(matrixStats)
library(cowplot)
library(grid)
library(circlize)
library(MASS)
library(giscoR)
library(radiator)
library(ggrepel)
```

## Load/Filter Data
```{r load filter data}
setwd("FilePath/With/RawVCF/And/Whitelist/And/PopMap/And/RegionFile")

#Read in VCF file
in_vcf <- read.vcfR("your_filename.vcf", convertNA = T)

#Convert vcf to genlight. Save twice: genlight.orig will be preserved if samples are subset and the genlight object will be replaced; if no subsetting is needed, then the file named genlight will be used throughout the rest of the script. 
genlight.orig = genlight <- vcfR2genlight(in_vcf)

#Read in the population map. This should be a two-column tab-delimited text file where the first column contains the name of each individual sample and the second column contains the population. This can be the same as the population map used in Stacks.
popmap.orig <- read_tsv("your_filename.txt", col_names = F) %>% 
  dplyr::rename(Indiv = X1, STRATA = X2)

#Filter the population map for whitelisted individuals i.e. those we will keep for the population genetics analysis.
popmap.filtered <- tibble(Indiv = genlight@ind.names) %>% left_join(popmap.orig, by = "Indiv")
genlight@pop <- as.factor(popmap.filtered$STRATA)
summary(genlight@pop)

#Read in a "regions" file. This file should have at a minimum a column for Population, latitude, and longitude. We assume this is a csv (comma-separate) file.
region <- read.csv("your_filename.csv", header = T)

#Tibbles will only show a couple sig digits for lat and long, but the full coordinates are stored.
latlon <- as.data.frame(cbind(region$Population,
                              region$lat,
                              region$lon)) %>% 
  dplyr::rename(STRATA = V1, lat = V2, lon = V3) %>% 
  mutate(lat = as.numeric(lat), lon = as.numeric(lon))

#Replicate the coordinates for each sample
all_latlon <- popmap.filtered %>% left_join(latlon, by = "STRATA") %>% 
  dplyr::select(-Indiv)

latlon <- all_latlon[,2:3]
genlight@other$latlon<-latlon

#Check compliance so that individuals and loci can be filtered
genlight_2 <- gl.compliance.check(genlight)

#Subset the full set of samples for analysis
#Only run this section if you want to run the analysis on a subset of individuals included in the filtered VCF file. If you want to run on all the samples in the vcf file that was loaded, then skip this section and move on to "Finish creating genlight and genind objects" a few lines below.
#Read in white list of individuals/locs. This should be a text file with a single column containing the names of the individuals that were retained after filtering.
whitelist.indvs <- read.delim("your_filename.txt", header = F, strip.white = T) %>% pull()
genlight_3 <- gl.keep.ind(genlight_2, ind.list = whitelist.indvs)
genlight_3@ind.names

whitelist.locs <- read.delim("your_filename.txt", header = F, strip.white = T) %>%
  dplyr::rename(Chrom = V1, Pos = V2) %>%
  arrange(Chrom, Pos)
whitelist.locs_2 <- str_c(whitelist.locs$Chrom, "_", whitelist.locs$Pos)
genlight_4 <-gl.keep.loc(genlight_3, loc.list = whitelist.locs_2, verbose=0)
rm(genlight, genlight_2, genlight_3)

#Finish creating genlight and genind objects
genind <- gl2gi(genlight_4) # need genind format for some functions
summary(genlight_4@pop)
summary(genind@pop)
```

## Basic Stats (e.g. Het., Fst)
```{r basic stats}
#Het et al.
dartR_het<-gl.report.heterozygosity(genlight_2)
dartR_het<-dartR_het %>%
    mutate_if(is.numeric, round, digits=3)

dartR_div<-gl.report.diversity(genlight_2)

write.csv(dartR_het, "het_stats.csv")

#Fst
fst_boot<-gl.fst.pop(genlight_4, nboots=10000, percent=95)
fst_boot_fsts<-data.matrix(round(fst_boot[["Fsts"]], 3))
fst_boot_ps<-data.matrix(round(fst_boot[["Pvalues"]], 10))
fst_boot_fsts
fst_boot_ps
```

## Relatedness
```{r relatedness}
#For this analysis, using KING and R1 estimators. This assumes you have completed upstream steps using NGSrelate & plink to identify related individuals in your data. See associated shell/R scripts.

#Import and subset NGSrelate output
ngsrelate_data<-read.csv("./ngsrelate.csv")
ngsrelate_data<-data %>%
  dplyr::select(c("ida", "idb", "R0", "R1", "KING"))
ngsrelate_data$label <- paste(data$ida, data$idb)

#Import and subset plink output
plink<-read.csv("./plink.csv", header=T)
plink<-plink %>%
  dplyr::select(c("IID1", "IID2", "Z0", "Z1", "Z2", "PI_HAT"))
plink$label<-paste(plink$IID1, plink$IID2)

#Merge the dataframes and assign kinship
alldata<-merge(data, plink)
alldata$kinship<-((alldata$Z1/4)+(alldata$Z2/2))
#Cutoffs = Unrelated < 0.044 < 3rd  < 0.088 < 2nd < 0.177 < FS/PO < 0.354 < Twins
alldata$Relationship<-cut(alldata$kinship,
                          breaks=c(-Inf, (1/(2^(9/2))), (1/(2^(7/2))), (1/(2^(5/2))), (1/(2^(3/2))), Inf),
                          labels=c("Unrelated", "3rd Degree", "2nd Degree", "FS/PO", "Twins"))
alldata$kplus0_01 <- alldata$kinship + 0.01
alldata$kminus0_01 <- alldata$kinship - 0.01

# Create a function to extract population abbreviations
extract_population <- function(individual) {
  # Extract population abbreviation by splitting at the numeric part
  Population <- gsub("\\d", "", individual)
  return(Population)
}

# Create a new column 'population' for each pair of individuals
alldata <- alldata %>%
  mutate(Population = ifelse(extract_population(ida) == extract_population(idb), 
                             extract_population(ida), 
                             paste(extract_population(ida), "-", extract_population(idb), sep = "")))

#Subset for internal population comparisons
#Can amend to only look at between population statistics by removing "!" before grepl
alldata_internal_pop <- alldata %>%
  filter(!grepl("-", Population))

alldata_internal_pop$Population <- factor(alldata_internal_pop$Population, levels = c("NRU", "CEFL", "SEFL", "DRTO", "SWFL", "CWFL", "NGM"))

#Plot King estimator vs R1 estimator and save as jpeg
jpeg("Combined_KINGvsR1_Relatedness.jpg", width = 6, height = 6, units = "in", res = 500)
alldata_internal_pop %>% ggplot(aes(R1, KING, label=label)) +
  geom_point(aes(color=Population), size=3, alpha=0.6) +
  theme_classic()+
  theme(axis.title = element_text(size=14, face="bold"), 
        axis.text = element_text(size=14, face="bold"))
dev.off()

#Make a violin plot of just King estimator
jpeg("Combined_KING__Violin_Relatedness.jpg", width = 6, height = 6, units = "in", res = 500)
alldata_internal_pop %>% 
  ggplot(aes(x=Population, y=KING)) + 
  geom_violin(trim=FALSE)+
  theme_classic()+
  geom_boxplot(width=0.1, color="black")
dev.off()

#Summarize King and R1 and export as CSV
pop_rel_stats <- alldata_internal_pop %>%
  group_by(Population) %>%
  summarize(
    MeanKING = mean(KING),
    MedianKING = median(KING),
    StdDevKING = sd(KING),
    MeanR1 = mean(R1),
    MedianR1 = median(R1),
    StdDevR1 = sd(R1)
  )

write.csv(pop_rel_stats, "Pop_Relatedness.csv")
```

## PCA
```{r PCA}
#PCAs 1v2 and 1v3 are exported as SVGs, as is the legend, to enable figure creation in a software such as premiere pro. Both PCAs and legend are viewed.

pca1 <- glPca(genlight_4,center = T, scale = T, nf = 5)
a1<-pca1$eig[1]/sum(pca1$eig) # proportion of variation explained by 1st axis
a2<-pca1$eig[2]/sum(pca1$eig) # proportion of variation explained by 2nd axis 
a3<-pca1$eig[3]/sum(pca1$eig) # proportion of variation explained by 3rd axis
pcvar <- data.frame(Axis = c(1:3), Proportion = c(a1,a2,a3))
pcvar

#Extract PC scores to color by location/yr:
#Adapted from https://github.com/grunwaldlab/Population_Genetics_in_R/blob/master/gbs_analysis.Rmd#principal-components-analysis

pca1.scores <- as.data.frame(pca1$scores)
pca1.scores$Population <- pop(genlight_4)
pca1.scores$reg <- pca1.scores$pop

#Make PCA plots
set.seed(9)
num_pops <- length(levels(factor(popmap.filtered$STRATA)))

# plot PC 1 and 2
PCA1_2<-ggscatter(pca1.scores, x = "PC2", y = "PC1", shape = "Population", color = "Population",
                  palette = pop_cols, size=4, ellipse = T, ellipse.level = 0.95,
                  xlab = paste0("PC2 (",round(pcvar[2,2]*100,2),"%)"),
                  ylab = paste0("PC1 (",round(pcvar[1,2]*100,2),"%)")) +
  scale_shape_manual(values=pop_shapes) +
  theme(legend.position="none") +
  #scale_y_continuous(limits=c(-110,80), breaks=c(-75, -50, -25, 0, 25, 50),
                     #labels=c("-75", "-50", "-25", "0", "25", "50"))+
  theme(panel.grid = element_blank(),
        #axis.title.x = element_blank(),
        axis.title = element_text(size=25, face="bold"), 
        axis.text = element_text(size=25))


# plot  PC 1 and 3
PCA1_3<-ggscatter(pca1.scores, x = "PC3", y = "PC1", shape = "Population", color = "Population",
                  palette = pop_cols, size=4, ellipse = T, ellipse.level = 0.95,
                  xlab = paste0("PC3 (",round(pcvar[3,2]*100,2),"%)"),
                  ylab = paste0("PC1 (",round(pcvar[1,2]*100,2),"%)"))+
  scale_shape_manual(values=pop_shapes) +
  theme(legend.position="none") +
  theme(panel.grid = element_blank(),
        axis.title.y = element_blank(),
        axis.title = element_text(size=25, face="bold"), 
        axis.text = element_text(size=25))


pcas<-grid.arrange(PCA1_2, PCA1_3, ncol=2, nrow=1)
ggsave(file="Figure1_PCAs.svg", plot=pcas, width=10, height=5)

#Extract Legend
PCA_Legend<-ggscatter(pca1.scores, x = "PC2", y = "PC1", shape = "Population", color = "Population",
                      palette = pop_cols, size=4, ellipse = T, ellipse.level = 0.95,
                      xlab = paste0("PC2 (",round(pcvar[2,2]*100,2),"%)"),
                      ylab = paste0("PC1 (",round(pcvar[1,2]*100,2),"%)")) +
  scale_shape_manual(values=pop_shapes) +
  theme(legend.title = element_text(size=20, face="bold"),
        legend.text = element_text(size=20)) +
  #scale_y_continuous(limits=c(-110,80), breaks=c(-75, -50, -25, 0, 25, 50),
  #labels=c("-75", "-50", "-25", "0", "25", "50"))+
  theme(panel.grid = element_blank(),
        #axis.title.x = element_blank(),
        axis.title = element_text(size=25, face="bold"), 
        axis.text = element_text(size=25))

#Export PCA legend
dev.off()
legend<-ggpubr::get_legend(PCA_Legend)
legend_plot<-as_ggplot(legend)
ggsave(file="Figure1_PCAs_legend.svg", plot=legend_plot, width=7, height=0.5) 

#View PCAS with legend
pcas<-grid.arrange(PCA1_2, PCA1_3, legend_plot, ncol=2, nrow=2)

```

## DAPC
```{r DAPC}
n_individuals <- nrow(popmap.filtered)
n_pops <- length(levels(factor(popmap.filtered$STRATA)))

#Search for optimal clusters in data
grp_all <- find.clusters(genind, max.n.clust=10, n.pca=200,
                         choose.n.clust = FALSE)

BIC<-as.data.frame(cbind(seq(1,10,1), grp_all$Kstat))

ggline(BIC, x = "V1", y = "V2", plot_type = "b",
       col = "navy",
       xlab = "Number of clusters (K)",
       ylab = "BIC Value",
       title = "Selection of optimum number of clusters (K)") + font("xlab", face = "bold") + font("ylab", face = "bold")
grp_all$Kstat

#Depending on BIC graph, may want to look into groupings identified using K-means. For this analysis (with loggerhead turtle SNP data) we will just see where our a priori populations fall out using a calibrated DAPC (using an optimized a-score technique)

#Calibrated DAPC
set.seed(5)
n.da<-6 #set number of DAs
dapc_a_score <- dapc(genind, n.pca=100, n.da=n.da) #Use many PCs
temp_score <- optim.a.score(dapc_a_score) #Determine best number of PCs to retain for DAPC analysis
n.pc <- temp_score$best #Save best number of PCs
dapc2 <-dapc(genind,genind@pop, n.pca = n.pc, n.da = n.da)
dapc2$IND <- row.names(dapc2$ind.coord)
dapc2_info <- as.data.frame(cbind(dapc2$IND, dapc2$ind.coord, grp_all$grp))

#Export DAPC coordinates as table
dapc_final <- as.data.frame(dapc2$ind.coord)
dapc_final$IND <- row.names(dapc_final)
dapc_final$SITE <- str_sub(dapc_final$IND, 1,2)
dapc_final$MU <- gsub("[^a-zA-Z]", "", dapc_final$IND) #Assumes the site is the first two characters of the individual names
dapc_final$MU <-as.factor(dapc_final$MU)

write.table(dapc_final, "DAPC_final_results.txt", quote=F, sep="\t", row.names=TRUE)

#Visualize second DAPC as scatterplot, export

scaled_LD <- as.data.frame(dapc2$ind.coord)
scaled_LD$LD1 <- scaled_LD$LD1 * sqrt(dapc2$eig[1])
scaled_LD$LD2 <- scaled_LD$LD2 * sqrt(dapc2$eig[2])
scaled_LD$LD3 <- scaled_LD$LD3 * sqrt(dapc2$eig[3])
scaled_LD$LD4 <- scaled_LD$LD4 * sqrt(dapc2$eig[4])
scaled_LD$LD5 <- scaled_LD$LD5 * sqrt(dapc2$eig[5])
scaled_LD$LD6 <- scaled_LD$LD6 * sqrt(dapc2$eig[6])
scaled_LD$IND <- dapc_final$IND
scaled_LD$MU <- dapc_final$MU
scaled_LD$MU <- factor(scaled_LD$MU, levels = c("NRU", "CEFL", "SEFL", "DRTO", "SWFL", "CWFL", "NGM"))

dapc_output<-scaled_LD %>%
  ggplot(aes(x = LD1, y = LD2)) +
  geom_point(aes(fill=MU), size = 4, pch=21, alpha=0.7) +  # Plot points for individuals
  stat_ellipse(aes(color=MU), type = "norm", level = 0.50) +  # Add 95% confidence ellipses around groups
  labs(
       x = paste0("DA1 (", round(dapc2$eig[1] / sum(dapc2$eig) * 100, 2), "%)"),
       y = paste0("DA2 (", round(dapc2$eig[2] / sum(dapc2$eig) * 100, 2), "%)")) +
  theme_classic() +
  theme(legend.position = "right",
        legend.text = element_text(size=12),
        legend.title = element_text(size=15),
        axis.text=element_text(size=12),
        axis.title = element_text(size=15))+
  scale_fill_manual(values = pop_cols) +
  scale_color_manual(values = pop_cols)

ggsave(file="DAPC_scatter.svg", plot=dapc_output, width=10, height=8)

#View assignment barplot
compoplot(dapc2)

#Make custom assignment barplot of second DAPC, beginning with assignments dataframe
assignments<-as.data.frame(dapc2$posterior)
assignments$pop<-gsub("[^a-zA-Z]", "", row.names(assignments))
assignments$pop<-as.factor(assignments$pop)
assignments$ind<-rownames(assignments)
assignments$post<- gsub("[^a-zA-Z]", "", colnames(assignments[,1:7])[max.col(assignments[,1:7],ties.method="first")])
assignments$post<-as.factor(assignments$post)
assignments_final<-assignments
assignments_final$correct<-ifelse(assignments_final$pop==assignments_final$post, "1", "0")
assignments_final$correct<-as.numeric(assignments_final$correct)

#Calculate percent correct reassignment per population
reassign.success<-assignments_final %>%
  group_by(pop) %>%
  summarize(
    prop.correct <- sum(correct)/length(correct)
  )

#Format assignments data for barplots
assign_melt<-melt(assignments)
assign_melt<-assign_melt%>%
  arrange(pop) %>%
  arrange(ind)

# Apply the function to reorder each list within the list of lists
reordered_inds <- reorder_list(assign_melt$ind)
reordered_inds
levels(reordered_inds) <- reordered_inds
assign_ind_table <- table(assign_melt$ind)
ind_levels <- names(assign_ind_table)[order(assign_ind_table)]
assign_melt$ind <- factor(assign_melt$ind, levels = assignments$ind)
assign_melt$pop <-factor(assign_melt$pop, levels = c("NRU", "CEFL", "SEFL", "DRTO", "SWFL", "CWFL", "NGM"))

compoplot_dapc2<-ggplot(assign_melt, 
       aes(fill=variable, y=value, x=ind),
       color = "variable")+ 
  geom_bar(position="fill", stat="identity")+
  theme_minimal()+
  scale_fill_manual(values=pop_cols)+
  theme(legend.position="none") +
  labs(y="Membership Probability", x="Individuals")+
  theme(panel.grid = element_blank(),
        axis.title = element_text(size=20, face="bold"), 
        axis.text = element_text(size=20),
        axis.text.x = element_blank())

compoplot_dapc2

#Save as SVG to add legend later
ggsave(file="DAPC_barplot.svg", plot=compoplot_dapc2, width=10, height=5) 

compoplot_dapc2_legend<-ggplot(assign_melt, 
                               aes(fill=variable, y=value, x=ind),
                               color = "variable")+ 
  geom_bar(position="fill", stat="identity")+
  theme_minimal()+
  scale_fill_manual(values=pop_cols, name= "Population")+
  theme(legend.title = element_text(size=20, face="bold"),
        legend.text = element_text(size=20))+
  labs(y="Membership Probability", x="Individuals")+
  theme(panel.grid = element_blank(),
        axis.title = element_text(size=20, face="bold"), 
        axis.text = element_text(size=20),
        axis.text.x = element_blank())

#Save legend as SVG
dev.off()
legend_compoplot<-ggpubr::get_legend(compoplot_dapc2_legend)
legend_comp_plot<-as_ggplot(legend_compoplot)
ggsave(file="DAPC_brplot_legend.svg", plot=legend_comp_plot)

```

##STRUCTURE/fastStructure 
```{r STRUCTURE}
#Assumes you have downloaded .meanQ or STRUCTURE run files into a directory. Code below uses pophelper to make nice barplots of STRUCTURE or fastStructure runs
setwd("Folder/With/STRUCTURE/Or/fastStructure/Files/")

#Different inputs for STRUCTURE vs fastStructure
#STRUCTURE:
sfile <- list.files(path="./") #can add pattern recognition as below if other non-STRUCTURE files exist in this directory
slist<-readQ(files=sfile, filetype="structure", indlabfromfile = TRUE)

#fastStructure
sfile<-list.files(path="./", pattern="\\.meanQ$") 
slist<-readQ(files=sfile) 

#For non-structure files, load individual names list and add to slist
inds<-read.delim("names.txt", header=F) #names.text is a text file with one line per individual with just the individual name
if(length(unique(sapply(slist,nrow)))==1) slist <- lapply(slist,"rownames<-",inds$V1)

#Tabulate/Summarize Runs
tab_slist<-tabulateQ(slist)
sum_slist<-summariseQ(tab_slist)

#Set WD for plot outputs if different than current WD
setwd("Where/You/Want/To/Save/Plots")

#Evanno Method only works for STRUCTURE runs
em <- evannoMethodStructure(data=sum_slist,exportplot=T,writetable=T,na.rm=T,exportpath=getwd())
p <- evannoMethodStructure(data=sum_slist,exportplot=F,returnplot=T,returndata=F,basesize=12,linesize=0.7)
grid.arrange(p)

#Align assignment probabilities
slist1 <- alignK(slist)

#Make group set for plotting
inds$MU <- gsub("[^a-zA-Z]", "", inds$V1)
for (m in 1:length(inds$MU)){
  if (inds$MU[m] == "NRU" || inds$MU[m] == "CEFL" || inds$MU[m] == "SEFL"){
    inds$OCE[m] <- "Atlantic Ocean"
  } 
  else { 
    if (inds$MU[m] == "DRTO" || inds$MU[m] == "SWFL" || inds$MU[m] == "CWFL" || inds$MU[m] == "NGM"){
      inds$OCE[m] <- "Gulf of Mexico"
    }
  }
}

groups <- inds[,2:3]

#Store assignment barplot as object and export
p1<- plotQ(slist1[c(15,25,35)], #Use slist1[c(#,#,#, etc.)] to plot selected runs
           imgoutput="join",
           returnplot=TRUE,
           exportplot=FALSE,
           basesize=11,
           showindlab = FALSE,
           grplab = groups,
           showgrplab = TRUE,
           ordergrp = FALSE,
           grplabsize = 5,
           grplabcol = "black",
           sharedindlab = FALSE,
           barbordersize=0,
           barbordercolour = "white",
           splab = c("K=2", "K=3", "K=4"),
           splabsize = 15,
           splabcol = "black",
           divgrp = "MU",
           divsize = 0.5,
           divcol = "black",
           divtype = 1,
           pointsize = 5,
           pointcol = "black",
           linesize = 0.5,
           linecol = "black")

grid.arrange(p1$plot[[1]])

png("STRUCTURE.png", width = 15, height = 10, units = "in", res = 500) 
grid.arrange(p1$plot[[1]])
dev.off()

ggsave("STRUCTURE.svg", plot = grid.arrange(p1$plot[[1]]), width = 15, height = 10)

```